---
layout: post
title: Kafka设计原理
categories: [Kafka]
description: Kafka设计原理
keywords: Kafka
---

### 持久化

Kafka严重依赖文件系统来存储和缓存消息。很多人固有观念是硬盘慢，怀疑这样的存储结构无法提供好的性能。但是硬盘是快还是慢取决与如何使用硬盘，如果设计合理的硬盘结构是能够和互联网一样快。

6个7200rpm SATA RAID5阵列上顺序写的性能是600MB/s，但是随机写只有100k/s，相差6000倍。顺序读写都是可预测的，所以操作系统能够极大的优化。现代操作系统提供了预读和后写技术，读的时候预取多个块的数据，将小部分逻辑写合并为的物理写操作。下图为各种存储介质的顺序访问性能对比：
![各种存储介质的顺序访问性能对比](https://github.com/qinchunabng/qinchunabng.github.io/blob/master/images/posts/kafka/jacobs3.jpg?raw=true)

由于这个性能差异，现代操作系统大量的使用主存作为硬盘的缓存。现代操作会将所有的空闲内存作为硬盘缓存，代价只有内存回收时较小的性能损耗。所有硬盘读写都将通过这个统一的缓存。如果不使用直接I/O，不要轻易关闭这个功能。即使一个进程内存维护一个进程内部的数据缓存，这个数据可能在操作系统的页缓存中同样存在一份，这样就导致数据重复存储。

此外，kafka是运行在JVM中的，java的内存使用有以下两个问题：

1. 对象内存开销非常大，经常是要存储数据的两倍（甚至更大）。
2. 随着堆内存的增长，Java垃圾回收会变得越来越繁琐和缓慢。

由于这些因素，使用文件系统存依赖页缓存要优于维护内存中的缓存或者其他结构。通过自动访问空闲内存，我们至少将可用内存翻了一倍，同时通过紧凑的字节结构而不是单独的对象，可能还会增长一倍。这么会导致32GB机器会产生28-30GB缓存，但是不会有GC问题。此外即使重启也能保证缓存中的数据都是最新的需要的，然而如果是进程内的缓存就需要重建（10GB缓存可能需要10分钟），或者重启之后不预热缓存（可能会导致初期性能严重下降）。把缓存和文件系统的一致性交给操作系统来完成，也极大的简化的代码的业务逻辑，这比在进程中自己维护缓存要高效的多。因为硬盘线性读拥有更好的性能，所以每次读取硬盘的时候将一些有用的数据一起读取到缓存中这种预读的方式，是很高效的。

所以一个简单而高效的设计就是：相比在内存中维护一个缓存并且在缓存不够的时候再将数据写入文件系统，还不如颠倒过来，将所有的数据直接写入到文件系统的日志文件中，但不必写入硬盘，实际上就只是写入的内核的页缓存中。

在消息系统中一般每个消费者消费一个队列，消息的存储结构一般要么是BTree或者是支持随机访问的维护了消息元数据的数据结构。Btree是最通用的数据结构，支持消息系统中的各种事务的和非事务的语义。但是维护Btree的代价比较高，虽然Btree操作的时间复杂度是O(log N)。一般情况，O(log N)的时间复杂度等同于常量时间，但是对于磁盘操作来说并不是。磁盘寻址一般需要10ms一次，每个磁盘每个时刻只能执行一次寻址，即使是少量的磁盘寻道都有很高的开销。所以存储系统通过更快的缓存来避免磁盘的物理操作，而在固定大小缓存下随着数据的增长树结构的性能下降是超线性的（比如数据增长一倍，性能下降超过一倍）。

持久化队列构建在简单的读取和追加文件上，是常见的日志解决方案。这种机构优势是所有的操作都是O(1)，并且读不会阻塞其他的读或者写。还有一个巨大的优点是性能不再和数据大小有关系，这样服务器就可以充分利用一些便宜的低转速的1+TB SATA驱动器。虽然它们寻址性能很差，但是可以以1/3的价格和三倍的容量获得可以接受的读写性能。

可以访问近乎无效的磁盘空间，而且没有任何性能损失，这意味着我们可以提供一些在消息系统不常见的特性。例如，在kafka中，消息被消费之后并不是立马被删除，消息会被保留相当长一段时间（一般是一周），这就给了消费者很大灵活性。

### 效率

在前面一节我们讨论如何消除磁盘访问慢的问题，但是还有两个原因会影响性能：大量的小的I/O操作和过多的数据拷贝。

小的I/O经常发生在服务器和客户端之间的交互时或者服务器本身执行持久化操作的时候。为了避免这种情况的发生，kafka将多个消息组装一起发送而不是单个单个的发送，来分摊网络的开销。kafka依次的将消息块追加到日志中，消费者消费的时候一次获取多个消息。

这个简单的优化使得速度提升了几个数量级。批量操作会产生更多的网络包，更大的有序的磁盘操作，连续的内存块等等，这些使得kafka将随机的写操作转变为线性的写操作。

另外一个影响性能的是数据拷贝。在消息量少的这不是一个问题，但是在高负载下对性能会产生巨大的影响。为了避免这个问题，kafka定义一个标准的二进制消息格式，在生产者、broker、消费者之间是通用的，这样数据在它们之间传输就不需要修改。

消息日志是由broker维护的文件目录，每个日志文件的内容都是同样格式的且有序的消息集，并且被写入到磁盘中。维持这个通用的消息格式可以允许优化最重要的操作：日志块网络传输。现代unix操作系统对从页缓存传输数据到socket中提供了高度的优化方法，在linux中是通过sendfile系统调用完成的。

要理解sendfile的对性能的影响，先要理解一般是怎么从文件中传输数据到socket的：

1. 操作系统从磁盘中读取数据到内核空间的页缓存中
2. 应用程序将数据从内核空间读到用户空间的缓存中
3. 应用程序将数据写入到内核空间的socket缓冲区
4. 操作系统将数据从socket缓冲区发送NIC缓冲区，在这里数据被发送的网络中。

这个过程中有四次数据拷贝和两个系统调用，对性能会有很大的影响。使用sendfile，允许操作系统直接将数据从页缓存发送到网络，从而避免了重复的数据拷贝，最终只需要最后一次到NIC缓冲区的拷贝。

kafka中一个常见的消费方式是多个消费者消费一个topic。使用零拷贝，之举只需要从磁盘到页缓存一次拷贝，每次消费都被重用，而不是把数据保存内存中，每次读取时都拷贝到用户空间。这使得消息的消费速度能达到接近网络连接的限制。

通过页缓存和sendfile的组合，使kafka集群中消费者能够达到极佳的性能，因为读操作几乎不需要访问磁盘所有的数据都在缓存中。

由于TLS/SSL库的操作是在用户空间（kafka目前还不支持内核的SSL_sendfile），在SSL开启时不会使用sendfile。