---
layout: post
title: Kafka设计原理
categories: [Kafka]
description: Kafka设计原理
keywords: Kafka
---

### 持久化

Kafka严重依赖文件系统来存储和缓存消息。很多人固有观念是硬盘慢，怀疑这样的存储结构无法提供好的性能。但是硬盘是快还是慢取决与如何使用硬盘，如果设计合理的硬盘结构是能够和互联网一样快。

6个7200rpm SATA RAID5阵列上顺序写的性能是600MB/s，但是随机写只有100k/s，相差6000倍。顺序读写都是可预测的，所以操作系统能够极大的优化。现代操作系统提供了预读和后写技术，读的时候预取多个块的数据，将小部分逻辑写合并为的物理写操作。下图为各种存储介质的顺序访问性能对比：

![各种存储介质的顺序访问性能对比](https://github.com/qinchunabng/qinchunabng.github.io/blob/master/images/posts/kafka/jacobs3.jpg?raw=true)

由于这个性能差异，现代操作系统大量的使用主存作为硬盘的缓存。现代操作会将所有的空闲内存作为硬盘缓存，代价只有内存回收时较小的性能损耗。所有硬盘读写都将通过这个统一的缓存。如果不使用直接I/O，不要轻易关闭这个功能。即使一个进程内存维护一个进程内部的数据缓存，这个数据可能在操作系统的页缓存中同样存在一份，这样就导致数据重复存储。

此外，kafka是运行在JVM中的，java的内存使用有以下两个问题：

1. 对象内存开销非常大，经常是要存储数据的两倍（甚至更大）。
2. 随着堆内存的增长，Java垃圾回收会变得越来越繁琐和缓慢。

由于这些因素，使用文件系统存依赖页缓存要优于维护内存中的缓存或者其他结构。通过自动访问空闲内存，我们至少将可用内存翻了一倍，同时通过紧凑的字节结构而不是单独的对象，可能还会增长一倍。这么会导致32GB机器会产生28-30GB缓存，但是不会有GC问题。此外即使重启也能保证缓存中的数据都是最新的需要的，然而如果是进程内的缓存就需要重建（10GB缓存可能需要10分钟），或者重启之后不预热缓存（可能会导致初期性能严重下降）。把缓存和文件系统的一致性交给操作系统来完成，也极大的简化的代码的业务逻辑，这比在进程中自己维护缓存要高效的多。因为硬盘线性读拥有更好的性能，所以每次读取硬盘的时候将一些有用的数据一起读取到缓存中这种预读的方式，是很高效的。

所以一个简单而高效的设计就是：相比在内存中维护一个缓存并且在缓存不够的时候再将数据写入文件系统，还不如颠倒过来，将所有的数据直接写入到文件系统的日志文件中，但不必写入硬盘，实际上就只是写入的内核的页缓存中。

在消息系统中一般每个消费者消费一个队列，消息的存储结构一般要么是BTree或者是支持随机访问的维护了消息元数据的数据结构。Btree是最通用的数据结构，支持消息系统中的各种事务的和非事务的语义。但是维护Btree的代价比较高，虽然Btree操作的时间复杂度是O(log N)。一般情况，O(log N)的时间复杂度等同于常量时间，但是对于磁盘操作来说并不是。磁盘寻址一般需要10ms一次，每个磁盘每个时刻只能执行一次寻址，即使是少量的磁盘寻道都有很高的开销。所以存储系统通过更快的缓存来避免磁盘的物理操作，而在固定大小缓存下随着数据的增长树结构的性能下降是超线性的（比如数据增长一倍，性能下降超过一倍）。

持久化队列构建在简单的读取和追加文件上，是常见的日志解决方案。这种机构优势是所有的操作都是O(1)，并且读不会阻塞其他的读或者写。还有一个巨大的优点是性能不再和数据大小有关系，这样服务器就可以充分利用一些便宜的低转速的1+TB SATA驱动器。虽然它们寻址性能很差，但是可以以1/3的价格和三倍的容量获得可以接受的读写性能。

可以访问近乎无效的磁盘空间，而且没有任何性能损失，这意味着我们可以提供一些在消息系统不常见的特性。例如，在kafka中，消息被消费之后并不是立马被删除，消息会被保留相当长一段时间（一般是一周），这就给了消费者很大灵活性。

### 效率

在前面一节我们讨论如何消除磁盘访问慢的问题，但是还有两个原因会影响性能：大量的小的I/O操作和过多的数据拷贝。

小的I/O经常发生在服务器和客户端之间的交互时或者服务器本身执行持久化操作的时候。为了避免这种情况的发生，kafka将多个消息组装一起发送而不是单个单个的发送，来分摊网络的开销。kafka依次的将消息块追加到日志中，消费者消费的时候一次获取多个消息。

这个简单的优化使得速度提升了几个数量级。批量操作会产生更多的网络包，更大的有序的磁盘操作，连续的内存块等等，这些使得kafka将随机的写操作转变为线性的写操作。

另外一个影响性能的是数据拷贝。在消息量少的这不是一个问题，但是在高负载下对性能会产生巨大的影响。为了避免这个问题，kafka定义一个标准的二进制消息格式，在生产者、broker、消费者之间是通用的，这样数据在它们之间传输就不需要修改。

消息日志是由broker维护的文件目录，每个日志文件的内容都是同样格式的且有序的消息集，并且被写入到磁盘中。维持这个通用的消息格式可以允许优化最重要的操作：日志块网络传输。现代unix操作系统对从页缓存传输数据到socket中提供了高度的优化方法，在linux中是通过sendfile系统调用完成的。

要理解sendfile的对性能的影响，先要理解一般是怎么从文件中传输数据到socket的：

1. 操作系统从磁盘中读取数据到内核空间的页缓存中
2. 应用程序将数据从内核空间读到用户空间的缓存中
3. 应用程序将数据写入到内核空间的socket缓冲区
4. 操作系统将数据从socket缓冲区发送NIC缓冲区，在这里数据被发送的网络中。

这个过程中有四次数据拷贝和两个系统调用，对性能会有很大的影响。使用sendfile，允许操作系统直接将数据从页缓存发送到网络，从而避免了重复的数据拷贝，最终只需要最后一次到NIC缓冲区的拷贝。

kafka中一个常见的消费方式是多个消费者消费一个topic。使用零拷贝，数据只需要从磁盘到页缓存拷贝一次，每次消费都被重用，而不是把数据保存内存中，每次读取时都拷贝到用户空间。这使得消息的消费速度能达到接近网络连接的限制。

通过页缓存和sendfile的组合，使kafka集群中消费者能够达到极佳的性能，因为读操作几乎不需要访问磁盘所有的数据都在缓存中。

由于TLS/SSL库的操作是在用户空间（kafka目前还不支持内核的SSL_sendfile），在SSL开启时不会使用sendfile。

java中零拷贝参考这篇[文章](https://qinchunabng.github.io/2023/03/16/java-zero-copy/)。

### 推模式和拉模式

Kafka使用了比较传统的设计，也是大多数消息采用的，生产者推送数据给broker，消费者从broker拉取消息。有些日志为中心的系统，采用的是推模式，主动给下游消费者推送数据。这两种方式各有有优缺点，推模式的系统缺点是难以控制给消费者推送数据的速率。一般来讲，消息者的目标是以最大的可能消费消息，但是在推模式下，消费者的消费速度很有可能会低于消息产生的速度，导致产生拒绝服务攻击。而拉模式消费取决于消费者自身，消费速度慢的时候就拉取速度就慢一些，消费地快就拉取的快。消费者可以通过一些补偿协议来表明消费者消费速度超过承受能力，继而调整消费速率。

另外一个拉模式的优点是消费者可以以一种比较好的方式批量拉取数据。推模式要么直接将消息推送给消费者，要么积累较多的数据一次推给消费者，但是无法确定下游的消费能否处理这些消息。为了低延迟，每次有消息的时候直接发送消息，但是在这样会造成性能的浪费。基于拉模式的设计总是拉取当前消费的位置之后所有的可用消息（或者固定数量的）。所以在批量处理的时候，延迟也较小。

拉模式的有一个缺点就是在broker没有数据的时候，消费者会一直空轮询，造成性能的浪费。为了避免这个问题，kafka在拉取的时候会带有一些参数，让消费者在长轮询的时候会一直阻塞，直到数据到来（或者等到有指定大小的数据到来时）。

### 消费者消费位置

追踪队列的消息位置，是消息系统性能的关键点之一。

大多数消息系统在将消息消费位置的元数据保存在broker中，所以当消息分发给消费者之后，broker要么直接直接记录下来，或者等待消费者发送确认。对于单服务器除了broker也没有其他的地方可以存储这个状态。因为大多数消息系统扩展性差，用这种数据结构存储是一个实用的选择。因为broker知道哪些消息消费了，就可以直接删除，可以保证存储的数据较小。

对于消费位置，broker和消费者很难达成一致。如果broker在消费分发给消费者之后直接记录消费位置，然后消费者消费消息失败，消息将会丢失。为了解决这个问题，很多消息系统添加确认机制，消息发送之后消费者之后，只是标记为已发送状态，等待消费者发送了确认消息之后，broker才记录消息为已消费状态。这种策略修复了丢消息的问题，但是又会导致新的问题。首先，如果消费已经处理了消息，但是没有发送确认消息，就会导致消息会被消费两次。另外一个问题就是性能问题，broker必须记录每个消息的多种状态（第一个状态为了防止消息第二次发送，第二个状态标记消息为已消费这样消息才能够被删除）。那么就有一些棘手的问题需要处理，比如消费发送但是没收到确认。

kafka使用不同方式处理这个问题。kafka的topic被分为了多个partition，每个消息在同一个时间只能被一个消费者组的一个消费者消费。这就意味着每个分区的消息者的消费位置只是一个整数，是下一个要消费消息的偏移量（offset）。这样消费的位置的状态就很简单，每个partition就一个数字。这样消息的确认机制就会很简单。

这样的处理方式还有另外一个好处就是，消费者可以随时调整消费的offset来重新消费。这违反消息的队列的规范，但是却带来一些好处。例如，如果一个消费者在消费了一些消息之后发现有bug，消费者可以在bug修复之后重新消费消息。

### 静态成员关系

静态成员关系是为了改善流式应用、消费者和其他一些构建在消费者组的再平衡协议之上应用的可用性。再平衡协议依赖于消费者组协调者的给消费者组的成员分配的实体ID。这些生成的ID是临时的，在消费者组成员重启或者加入时会改变。对于基于应用的消费者，这种动态的成员关系，在代码部署、配置更新或者重启时会导致大规模消费者实例的任务重新分配。对于一些应用，被打乱的任务需要很长时间才能恢复本地的状态，并且会导致的应用变为部分可用或者完全不可用。基于这个原因，kafka消费者组管理协议允许消费者提供一个永久的ID。组成员关系基于这些ID保持不变，因此就再平衡就不会触发。

如果你想使用静态成员关系，

- 升级broker和客户端的版本为2.3或2.3以上的版本，并且确认升级之后的broker使用`inter.broker.protocol.version`的协议版本是2.3或2.3以上。
- 通过`ConsumerConfig#GROUP_INSTANCE_ID_CONFIG`给消费者组的每个消费者设置一个唯一值。
- 对于kafka streams的应用，通过`ConsumerConfig#GROUP_INSTANCE_ID_CONFIG`给每个KafkaStreams实例设置一个唯一值。
  
如果你的broker版本低于2.3，但是在客户端设置了`ConsumerConfig#GROUP_INSTANCE_ID_CONFIG`，应用会检查broker版本，然后抛出一个UnsupportedException的异常。如果你设置了重复的ID值，broker检查机制会检查出来，然后通知ID重复的客户端，触发`org.apache.kafka.common.errors.FencedInstanceIdException`使客户端停止。

### 消息发送语义

kafka提供三种消息投递的保证：

- At most once: 消息可能会丢失，但是不会被重发。
- At least once: 消息不会丢失，但是会被重发。
- Exactly once: 每个消息只会被发送一次而且只有一次。

这就带来了两个问题：发送的消息的持久化保证和消费消息的持久化保证。

kafka中，发送的消息有提交的概念。一个消息一旦被提交，只要一个有写入消息的partition的broker存活，消息就不会丢失。如果一个生产者发送一个消息，并且遇上了网络错误，生产者是没有把办法确定这个错误是发送在消息被提交前还是提交后。这就类似向一个有自增列中的表中插入数据。

在0.11.0.0之前，如果生产者没有收到表示消息已经被提交的消息，生产者只能选择重发消息。这就提供了at-least-once的语义，因为如果原始的消息已经处理成功，消费重新发送会导致消息再次被写入日志中。从 0.11.0.0开始，kafka生产者支持幂等性发送选项，保证消息重新发送不会在日志中重复。为了实现消息发送的幂等性，broker会给每个生产者分配一个ID，生产者发送的每个不重复的消息会带有一个序号。从0.11.0.0开始，生产者支持使用类事务的语义将消息发送给多个topic partition：要么所有消息都写入成功，要么一个都不写入。这个主要用于多个kafka topic的精确一次处理。

不是所有的使用场景都要求这样强的保证。对延迟比较敏感的场景，生产者可以定义它需要的持久化等级。如果生产者定义需要等待消息被提供，发送成功需要10ms。生产者也可以通过配置，设置消息异步发送，或者只需要leader写入消息成功。

再从消费者视角来讨论这几种语义。所有副本都有同样的日志和同样的offset。消费者来控制消费的offset。如果消费者从不会挂机，可以将这个position保存在内存中，如果消费挂了我们希望另外一个消费者进程来接手，新的消费者进程需要选择一个合适的position来开始消费消息。消费者消费消息，更新消费的position有几种方式：
- 可以在读取消息之后，在日志中保存消费的位置，然后再消费消息。这种情况下，消费者进程在保存消费位置之后，但是还没有保存消费的输出结果时，可能会挂掉。这种情况，接管的消费者进程会从保存的消费位置继续消费，就会导致有些消息没有被真正的处理。这就对应了最多一次的语义，因为消费者挂掉之后，消息可能就不会被处理。
- 读取消息，处理消息，最后再保存消费的位置。这种情况下，可能会出现消息已经处理了，但是还没有保存消费位置，消费者进程挂了。这时，接管的消费者进程处理的前面一部分消息可能是已经被处理过的。这就对应at-least-once的语义。在大多数场景，消息都有一个主键值，可以用来实现幂等性更新（收到同样的消息的两次，只需要覆盖写入的记录）。

那么什么是exactly-once语义？当从一个kafka topic消费消息之后，生产消费发送到另外一个topic，我们可以利用0.11.0.0中新加的事务来处理。消费者消费的位置是存储在一个topic中消息，所以我们可以将写入offset到kafka和发送结果处理数据到另外一个topic放到一个事务中。如果是被终止，消费者的position会恢复到旧的位置，并且生成数据到另外一个topic消息对其他的消费不可见，这个取决于它的隔离级别。在默认read_uncommitted的隔离级别下，所有消息对消费者都可见，即使这些消息是属于一个中断的事务。但是在read_committed下，消费只能看到已经提交的事务的消息。

当写入到外部系统，消费者消费位置和消费输出结果存储要处理好。一般都是在存储消费位置和存储消费输出结果引入两阶段提交。但是也可以将消费位置和消费输出结果存储到同样的地方，通过这种简单方式解决。这种处理方式更好，因为很多存储输出结果的存储系统不支持两阶段提交。