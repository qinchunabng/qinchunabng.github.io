---
layout: post
title: 记一次跟kafka相关的生产故障
categories: [java]
description: 生产事故问题分析
keywords: java, kafka
---

最近生产环境遇到一个问题，觉得这个问题还是挺典型的，所以就把这个问题给记录下来。

### 问题现象
前几天，很多用户反馈App登录不上，后经查询服务端日志，发现很多数据库锁等待超时的异常。经过运维检查，服务器CPU占用很高，达到百分之九十多，而且有150w个回滚事务在执行。

### 原因分析

分析服务器日志，根据异常堆栈信息定位到代码位置，经过分析代码，大致分析原因为如下：

客户端在登录操作之后，会发送一个登录成功的kafka消息，在kafka监听消费消息，异步处理，更新账号相关的登录信息，提高登录接口的响应速度。正常情况下，消息中包含有登录的设备唯一拥有的设备ID，服务端根据这个设备ID从数据库查询出符合条件的数据然后再更新，但是由于偶然的原因客户端传过来的设备ID是一个空字符，导致查询会整表数据再去执行了update操作，而且update语句查询条件没有建立索引，会导致锁表。并且在早上上班高峰期，会有大量用户执行登录操作，就导致很多数据库操作获取不到锁而超时。并且这些操作都是在kafka监听中处理的，消费失败会导致重复消费，以致大量的数据库操作把数据资源耗尽。

**原因总结：不合理的数据库操作导致锁表，kafka消费失败重试导致不合理的数据库操作累积，耗尽数据库资源。**

### 解决办法

根据问题原因分析，应该从两个方面来解决问题：

**一. 从数据库方面，解决锁表的问题。**

首先，我们了解一下MySQL InnoDB的锁机制。

##### 共享锁和独占锁

InnoDB实现了共享锁和独占锁两种行级锁。

- 在事务中读取一行数据的时候会加共享(S)锁。

- 在事务中更新或者删除一行的时候会加独占(X)锁。

如果事务T1持有数据行r的S锁，另一个事务T2对数据行r的锁申请处理如下：

- 如果事务T2是申请加S锁，可以加锁成功，事务T1和T2同时持有数据行r的S锁。

- 如果事务T2是获取的X锁，则无法获取X锁。

如果事务T1获取的是X锁，则事务T2无论是获取S锁和X锁都无法获取成功，事务T2需要等到事务T1释放锁才能获取锁。
##### 意向锁

意向锁是表级锁，表明事务稍后会申请对数据行的共享或独占锁。InnoDB中又两种意向锁：

- 意向共享(IS)锁，表示一个事务准备给表中的数据加共享锁。

- 意向独占(IX)锁，标识一个事务准备给表中的数据加独占锁。

例如：`SELECT...FOR SHARE`会设置意向共享锁，`SELECT...FOR UPDATE`会设置意向独占锁。

意向锁的加锁规则如下：

- 一个事务在获取一行数据的共享锁之前，必须先获取IS锁或者更强的锁。

- 一个事务在获取一行数据的独占锁之前，必须先获取IX锁。

意向锁与共享锁独占锁的兼容性如下表所示：

||X|IX|S|IS|
|:---|:---:|---:|---:|---:|
|X|冲突|冲突|冲突|冲突|
|IX|冲突|兼容|冲突|兼容|
|S|冲突|冲突|兼容|兼容|
|IS|冲突|兼容|兼容|兼容|

如果一个事务的锁请求与当前已存在的锁兼容，那么这个事务获取锁成功，否则无法获取到锁，需要等到锁释放之后才能获取锁。因为冲突的锁之间可能会导致思索。意向锁除了整表请求（例如：`LOCK TABLES...WRITE`）不会锁任何东西，意向锁的主要目的是表明将要锁某一行数据或者某一行数据已经加锁。

##### 记录锁

记录锁是索引记录上的锁。例如:`SELECT c1 FROM t WHERE c1 = 10 FOR UPDATE;`会阻止其他事务插入、更新和删除t.c1=10的数据行。记录锁需要通过索引来加锁，如果一个表没有索引，InnoDB会创建一个隐藏的聚集索引来加记录锁。

##### 间隙锁

间隙锁是索引记录之间间隙的锁，或者说是第一个索引记录之前或最后一个索引记录之后的间隙锁。例如：`SELECT t1 FROM t WHERE c1 BETWEEN 10 AND 20 FOR UPDATE;`会阻止其他事务插入t.c1=15的数据行到表中，无论表中是否已经有该数据都会阻止，因为10到20之间的间隙已经加锁。

间隙锁是性能和并发之间的一个权衡，InnoDB中一些事务隔离级别会用到间隙锁。

使用唯一索引作为条件查询的SQL语句不会加间隙锁（不包含多列唯一索引的情况）。例如，下面的SQL语句中，如果id是唯一索引，只会给id等于10的记录加记录锁，不会阻止其他会话插入id<100的数据。

```
SELECT * FROM child WHERE id=100;
```
如果id不是一个索引或者不是唯一索引，会锁住id<100的间隙。

**二.从kafka消费着手，解决kafka重复消费的问题。**